{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install mlflow\n",
    "# pip install pysftp\n",
    "# conda install psycopg2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import mlflow\n",
    "import subprocess\n",
    "import git\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pickle\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "SSH_USER = \"artinmajdi\"\n",
    "DATABASE = 'chest_db_v2'\n",
    "DATABASE_USER_PASSWORD = 1234\n",
    "EXPERIMENT_NAME        = 'label_inter_dependence'\n",
    "\n",
    "SSH_HOST     = \"data7-db1.cyverse.org\"\n",
    "SSH_KEY      = \"~/.ssh/id_rsa\"\n",
    "LOCAL_PORT   = 5000\n",
    "ARTIFACT_DIR = \"/home/artinmajdi/mlflow_data/artifact_store\"\n",
    "SSH_PORT     = 5432"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ssh-tunneling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "************************************************\n",
      "Access is restricted to AUTHORIZED USERS only! If\n",
      "you are not authorized LEAVE NOW!\n",
      "************************************************\n",
      "\n",
      "\n",
      "\n",
      "bind [127.0.0.1]:5000: Address already in use\n",
      "channel_setup_fwd_listener_tcpip: cannot listen to port: 5000\n",
      "Could not request local forwarding.\n"
     ]
    }
   ],
   "source": [
    "def ssh_tunneling(LOCAL_PORT=\"LOCAL_PORT\", SSH_PORT=\"SSH_PORT\", SSH_HOST='SSH_HOST', SSH_USER='SSH_USER', SSH_KEY='SSH_KEY'):\n",
    "        \n",
    "    \"\"\"  Open a SSH tunnel from a local port to a remote host.\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        SSH_HOST : str\n",
    "            Hostname or IP address of the machine to tunnel to.\n",
    "        SSH_PORT : int\n",
    "            Port on the remote machine to tunnel to.\n",
    "        SSH_USER : str\n",
    "            Username for SSH authentication.\n",
    "        SSH_KEY : str\n",
    "            Path to the SSH private key file.\n",
    "        LOCAL_PORT : int, optional\n",
    "            Local port to bind to.\n",
    "\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        tunnel : SSHClient\n",
    "            SSH client used to create the tunnel.\n",
    "                \n",
    "                    \n",
    "        Command (in CLI)\n",
    "        -------\n",
    "            > ssh -L -N {LOCAL_PORT}:localhost:{SSH_PORT} -i {SSH_KEY} {SSH_USER}@{SSH_HOST} &\n",
    "            \n",
    "            \n",
    "        Saving the ssh credentials (in CLI)\n",
    "        --------------------------\n",
    "            > ssh-keygen -t rsa\n",
    "            > ssh-copy-id -i {SSH_KEY}  {SSH_USER}@{SSH_HOST}\n",
    "\n",
    "\n",
    "        Killing the ssh-tunnel (in SCRIPT)\n",
    "        ----------------------\n",
    "            > ssh_session.kill()\n",
    "            \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    if SSH_HOST  is None: SSH_HOST = os.environ['REMOTE_HOST']\n",
    "    if SSH_USER  is None: SSH_USER = os.environ['REMOTE_USER']\n",
    "    if SSH_KEY   is None: SSH_KEY  = os.environ['REMOTE_PKEY']\n",
    "    \n",
    "    command = f'ssh -N -L {LOCAL_PORT}:localhost:{SSH_PORT} -i {SSH_KEY} {SSH_USER}@{SSH_HOST} &'\n",
    "    \n",
    "    ssh_session = subprocess.Popen('exec ' + command, stdout=subprocess.PIPE, shell=True)\n",
    "    \n",
    "    return ssh_session\n",
    "\n",
    "\n",
    "# Example:\n",
    "ssh_session = ssh_tunneling(LOCAL_PORT = LOCAL_PORT, \n",
    "                            SSH_PORT   = SSH_PORT, \n",
    "                            SSH_HOST   = SSH_HOST, \n",
    "                            SSH_USER   = SSH_USER, \n",
    "                            SSH_KEY    = SSH_KEY)\n",
    "\n",
    "# ssh_session.kill()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLFlow UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-05-14 00:39:54 -0700] [13823] [INFO] Starting gunicorn 20.1.0\n",
      "[2022-05-14 00:39:54 -0700] [13823] [INFO] Listening at: http://127.0.0.1:6789 (13823)\n",
      "[2022-05-14 00:39:54 -0700] [13823] [INFO] Using worker: sync\n",
      "[2022-05-14 00:39:54 -0700] [13825] [INFO] Booting worker with pid: 13825\n"
     ]
    }
   ],
   "source": [
    "def mlflow_ui(SSH_USER='SSH_USER', DATABASE_USER_PASSWORD='1234', LOCAL_PORT=5000, DATABASE='DATABASE', VIEW_PORT=6789):\n",
    "    \n",
    "    \"\"\" Running the ui locally\n",
    "    \n",
    "    Args:\n",
    "        VIEW_PORT (int, default=6789): port used for viewing mlflow server.\n",
    "    \"\"\"\n",
    "    \n",
    "    if subprocess.call(['nc', '-z', 'localhost', str(VIEW_PORT)]) == 0: \n",
    "        \n",
    "        print(f\"MLFlow UI is already running on localhost:{VIEW_PORT}\")\n",
    "        return None\n",
    "\n",
    "    command = f'mlflow ui --backend-store-uri postgresql://{SSH_USER}:{DATABASE_USER_PASSWORD}@localhost:{LOCAL_PORT}/{DATABASE} --port {VIEW_PORT}'\n",
    "    \n",
    "    p = subprocess.Popen('exec ' + command, stdout=subprocess.PIPE, shell=True)\n",
    "    \n",
    "    return p\n",
    "\n",
    "\n",
    "# Example:\n",
    "p = mlflow_ui(SSH_USER   = SSH_USER, \n",
    "              LOCAL_PORT = LOCAL_PORT, \n",
    "              DATABASE   = DATABASE, \n",
    "              VIEW_PORT  = 6789,\n",
    "              DATABASE_USER_PASSWORD = DATABASE_USER_PASSWORD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting MLFlow tracking and artifact servers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlflow_settings(LOCAL_PORT=\"LOCAL_PORT\", SSH_PORT=\"SSH_PORT\", SSH_HOST='SSH_HOST', DATABASE_USER_PASSWORD='1234', SSH_USER='SSH_USER', DATABASE='aiira', ARTIFACT_DIR='ARTIFACT_DIR', REMOTE_LOCAL='local'):\n",
    "    \n",
    "    \"\"\" Postgres server can be set to either the local port (mapped to remote port through ssh-tunneling) or directly with the remote port.\n",
    "                \n",
    "                            PORT     HOST \n",
    "                            ----    -----------------------\n",
    "        Remote Server:    5432    'data7-db1.cyverse.org'\n",
    "        Local  Server:    5000    'localhost'\n",
    "        \n",
    "        PostgreSQL Server: f'{dialect_driver}://{username}:{password}@{ip}/{database_name}' \n",
    "        \n",
    "        Artifact Server:   f'sftp://{username}@{host}:{path_to_artifact_store}' \n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "    HOST = SSH_HOST if REMOTE_LOCAL == 'remote' else 'localhost'\n",
    "    PORT = SSH_PORT if REMOTE_LOCAL == 'remote' else LOCAL_PORT\n",
    "        \n",
    "    server = f'postgresql://{SSH_USER}:{DATABASE_USER_PASSWORD}@{HOST}:{PORT}/{DATABASE}'\n",
    "    \n",
    "    \n",
    "    \"\"\" Artifact store is always kept on the remote server in this particular example.\n",
    "        \n",
    "        The artifact store is the location where clients log their artifact output (such as an S3 bucket or shared NFS file) (for example, models). \n",
    "        \n",
    "        Notes:\n",
    "            - Artifact location: is a property recorded in \"mlflow.entities.Experiment\" for all runs of this experiment. \n",
    "            - Artifact uri: is a property recorded in \"mlflow.entities.RunInfo\" that specifies the location of all artifacts for this run.\n",
    "\n",
    "        In each run, the MLflow client stores the location of artifacts. It is therefore not advised to alter the artifact location of a run before it has finished.\n",
    "\n",
    "        We can set the default artifact storage location with —default-artifact-root. (default: ./mlruns in local directory) \n",
    "        \n",
    "        Notes:\n",
    "            - This will be used for new experiments that do not provide an artifact location. \n",
    "            - -default-artifact-root is no longer valid once an experiment has been setup.\n",
    "            - Using the —serve-artifacts flag enables proxying of artifacts. It replaces an explicit artifact storage location (such as \"s3:/my bucket/mlartifacts\") with an implicit location. Sending HTTP requests to the MLflow Tracking Server does this. When publishing or retrieving artifacts, this avoids the need to configure access tokens or username/password environment variables for the underlying object storage.\n",
    "\n",
    "        SUPPORTED ARTIFACT STORES:\n",
    "    \n",
    "            - Amazon S3 and S3-compatible storage\n",
    "            - Azure Blob Storage\n",
    "            - Google Cloud Storage\n",
    "            - FTP server\n",
    "            - SFTP Server\n",
    "            - NFS\n",
    "            - HDFS\n",
    "    \"\"\"\n",
    "    \n",
    "    artifact = f'sftp://{SSH_USER}@{SSH_HOST}:{ARTIFACT_DIR}'\n",
    "\n",
    "    return server, artifact\n",
    "\n",
    "\n",
    "# Example:\n",
    "server, artifact = mlflow_settings( LOCAL_PORT = LOCAL_PORT, \n",
    "                                    SSH_USER   = SSH_USER, \n",
    "                                    SSH_PORT   = SSH_PORT, \n",
    "                                    SSH_HOST   = SSH_HOST, \n",
    "                                    DATABASE   = DATABASE,\n",
    "                                    REMOTE_LOCAL  = 'remote',\n",
    "                                    ARTIFACT_DIR = ARTIFACT_DIR,\n",
    "                                    DATABASE_USER_PASSWORD = DATABASE_USER_PASSWORD)                           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set tracking URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(server)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_setup(experiment_name='experiment_name', artifact=''):\n",
    "    \n",
    "    \"\"\" Setting up the experiment \"\"\"\n",
    "    \n",
    "    # Checking if the experiment exist\n",
    "    client = mlflow.tracking.MlflowClient()\n",
    "    \n",
    "    if not client.get_experiment_by_name(experiment_name):\n",
    "            \n",
    "        # creating the experiment\n",
    "        mlflow.create_experiment(name=experiment_name, artifact_location=artifact)\n",
    "\n",
    "    # setting the experiment\n",
    "    mlflow.set_experiment(experiment_name=experiment_name)\n",
    "    \n",
    "    return client\n",
    "\n",
    "\n",
    "\n",
    "# Example:\n",
    "client = experiment_setup(experiment_name=EXPERIMENT_NAME, artifact=ARTIFACT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLflow set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the optimization parameters aturomatically from keras\n",
    "mlflow.keras.autolog()\n",
    "\n",
    "# Starting the MLflow \n",
    "mlflow.start_run(run_name = 'Uncertainty Measurement')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the Info for an existing MLFlow Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getting_the_list_of_all_runs(experiment_name):\n",
    "    \n",
    "    \"\"\" Getting the list of all runs \"\"\"\n",
    "    \n",
    "    # Getting the list of all runs\n",
    "    # runs = mlflow.search_runs()\n",
    "\n",
    "    # setting up the tracking and artifact URI\n",
    "    client = mlflow.tracking.MlflowClient()\n",
    "\n",
    "    # finding the experiment id\n",
    "    experiment_id = client.get_experiment_by_name(experiment_name).experiment_id\n",
    "\n",
    "    # getting all the simulations/runs for experiment \"experiment_name\"\n",
    "    run_info_list = client.list_run_infos(experiment_id=experiment_id)\n",
    "    \n",
    "    return run_info_list\n",
    "\n",
    "\n",
    "\n",
    "# Example:\n",
    "run_info_list = getting_the_list_of_all_runs(experiment_name=EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaned up until this point\n",
    "---------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating an MLFlow Run from Old Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = run_info_list[0].run_id\n",
    "\n",
    "run    = mlflow.get_run(run_id=run_id)\n",
    "\n",
    "\n",
    "\n",
    "session_parent = mlflow.start_run(run_id='45512fa086574aef99fb49eaa2239ed8') # run_name='effect of adding uncertain samples to dataset - whole dataset')\n",
    "# mlflow.set_tag(f'mlflow.note.content',f'run_id: {session_parent.info.run_id}')\n",
    "\n",
    "\n",
    "session_new = mlflow.start_run(run_name='with uncertain sampels - whole dataset', nested=True)\n",
    "mlflow.set_tag(f'mlflow.note.content',f'run_id: {session_new.info.run_id}')\n",
    "\n",
    "\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "local_dir = '../../temp_without_unc'\n",
    "os.mkdir(local_dir)\n",
    "full_path = client.download_artifacts(run_id=run_id_source, path='', dst_path=local_dir)\n",
    "\n",
    "# run = mlflow.active_run()\n",
    "\n",
    "# logging the parameters, metrics, artifacts, and tags\n",
    "mlflow.log_params(session_source.data.params)\n",
    "mlflow.log_metrics(session_source.data.metrics)\n",
    "mlflow.log_artifact(full_path + 'model',artifact_path='')\n",
    "# mlflow.log_artifact(full_path + 'model_summary.txt',artifact_path='')\n",
    "\n",
    "\n",
    "repo = git.Repo(search_parent_directories=True)\n",
    "mlflow.set_tag('mlflow.source.git.commit', repo.head.object.hexsha)\n",
    "mlflow.set_tag('mlflow.source.name'      , session_source.data.tags['mlflow.source.name'])\n",
    "\n",
    "\n",
    "\n",
    "# tf.keras.models.load_model()\n",
    "# model = mlflow.keras.load_model(model_uri=f'runs:/{run_id_parent}/model',compile=False)\n",
    "# mlflow.keras.log_artifact(model,artifact_path='',conda_env='../conda.yaml')\n",
    "\n",
    "\n",
    "#  Writing on top of the page of run\n",
    "mlflow.set_tag(f'mlflow.note.content',f'run_id: {session_new.info.run_id}')\n",
    "\n",
    "\n",
    "# closing the mlflow session\n",
    "mlflow.end_run()\n",
    "\n",
    "# closing the mlflow session\n",
    "mlflow.end_run()\n",
    "\n",
    "# closing the ssh session\n",
    "ssh_session.kill()\n",
    "\n",
    "print('finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Duplicating a run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# starting the ssh session\n",
    "ssh_session = ssh_tunneling():\n",
    "\n",
    "# setting the tracking uri\n",
    "server, artifact = funcs.mlflow_settings()\n",
    "mlflow.set_tracking_uri(server)\n",
    "\n",
    "# creating the experiment\n",
    "experiment_name = 'expanding_dataset_aim1_2'\n",
    "mlflow.set_experiment(experiment_name=experiment_name)\n",
    "\n",
    "# downloading the source artifacts\n",
    "run_id_parent = 'bc306d0c76b94e19845f442f143fd5df'\n",
    "\n",
    "old_run = mlflow.get_run(run_id_parent)\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "local_dir = '../../temp_duplicate3' \n",
    "os.mkdir(local_dir)\n",
    "full_path = client.download_artifacts(run_id_parent, '', local_dir)\n",
    "\n",
    "\n",
    "run = mlflow.start_run(run_name='with uncertain sampels - whole dataset')\n",
    "\n",
    "mlflow.set_tag(f'mlflow.note.content',f'run_id: {run.info.run_id}')\n",
    "\n",
    "# logging the parameters, metrics, artifacts, and tags\n",
    "mlflow.log_params(old_run.data.params)\n",
    "mlflow.log_metrics(old_run.data.metrics)\n",
    "\n",
    "repo = git.Repo(search_parent_directories=True)\n",
    "mlflow.set_tag('mlflow.source.git.commit', repo.head.object.hexsha)\n",
    "mlflow.set_tag('mlflow.source.name'      , old_run.data.tags['mlflow.source.name'])\n",
    "mlflow.set_tag('mlflow.log-model.history', old_run.data.tags['mlflow.log-model.history'])\n",
    "\n",
    "\n",
    "model = mlflow.keras.load_model(model_uri=f'runs:/{run_id_parent}/model',compile=False)\n",
    "mlflow.keras.log_model(model,artifact_path='model',conda_env='../conda.yaml')\n",
    "\n",
    "# mlflow.log_artifact(full_path + 'model',artifact_path='')\n",
    "# mlflow.log_artifact(full_path + 'model_summary.txt',artifact_path='')\n",
    "# mlflow.log_artifact(full_path + 'conda.yaml',artifact_path='')\n",
    "\n",
    "# mlflow.log_artifact(full_path + 'train_val_142_samples',artifact_path='')\n",
    "# mlflow.log_artifact(full_path + 'train_val_full',artifact_path='')\n",
    "# mlflow.log_artifact(full_path + 'test',artifact_path='')\n",
    "\n",
    "\n",
    "\n",
    "# closing the mlflow session\n",
    "mlflow.end_run()\n",
    "\n",
    "# # closing the ssh session\n",
    "ssh_session.kill()\n",
    "\n",
    "print('finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading the artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# startin the ssh session\n",
    "ssh_session = ssh_tunneling():\n",
    "\n",
    "# setting the tracking uri\n",
    "server, artifact = funcs.mlflow_settings()\n",
    "mlflow.set_tracking_uri(server)\n",
    "\n",
    "# Downloading the artifact\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "run_id = '468f7bb48d4244dd8ebb7b5885e89d28'\n",
    "local_dir = '/home/u29/mohammadsmajdi/projects/chest_xray/'\n",
    "artifact_name = 'test_results.json'\n",
    "full_path = client.download_artifacts(run_id, artifact_name, local_dir)\n",
    "\n",
    "# loading the json file\n",
    "score = pd.read_json(full_path)\n",
    "\n",
    "# closing the ssh session\n",
    "ssh_session.kill()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resuming an existing mlflow session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'chexpert'\n",
    "dir = '/groups/jjrodrig/projects/chest/dataset/' + dataset + '/'\n",
    "\n",
    "# startin the ssh session\n",
    "ssh_session = ssh_tunneling():\n",
    "\n",
    "# setting the tracking uri\n",
    "server, artifact = funcs.mlflow_settings()\n",
    "mlflow.set_tracking_uri(server)\n",
    "\n",
    "mlflow.set_experiment(experiment_name='expanding_dataset_aim1_2')\n",
    "mlflow.start_run(run_id='45512fa086574aef99fb49eaa2239ed8')\n",
    "\n",
    "full_path  = '/home/u29/mohammadsmajdi/'\n",
    "mlflow.log_artifact(full_path + 'accuracy comparisons.xlsx',artifact_path='')\n",
    "mlflow.log_artifact(full_path + 'test.csv',artifact_path='')\n",
    "mlflow.log_params({'max_sample':1000000,'architecture_name':'DenseNet121', 'batch_size':50,'epochs':3,'number_augmentation':3,'learning_rate':0.001})\n",
    "\n",
    "\n",
    "# closing the mlflow session\n",
    "mlflow.end_run()\n",
    "\n",
    "# closing the ssh session\n",
    "ssh_session.kill()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the Git commit  (only in Jupyter notebook)\n",
    "This is only needed for jupyter notebook\n",
    "\n",
    "You can annotate runs with arbitrary tags. Tag keys that start with mlflow. are reserved for internal use. The following tags are set automatically by MLflow, when appropriate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo = git.Repo(search_parent_directories=True)\n",
    "git_commit_hash = repo.head.object.hexsha\n",
    "print('git commit hash', git_commit_hash)\n",
    "mlflow.set_tag('mlflow.source.git.commit', git_commit_hash)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nested run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# startin the ssh session\n",
    "ssh_session = ssh_tunneling():\n",
    "\n",
    "# setting the tracking uri\n",
    "server, artifact = funcs.mlflow_settings()\n",
    "mlflow.set_tracking_uri(server)\n",
    "\n",
    "# creating the experiment\n",
    "# mlflow.create_experiment(name='label_inter_dependence', artifact_location=artifact)\n",
    "mlflow.set_experiment(experiment_name='label_inter_dependence')\n",
    "\n",
    "# Create nested runs\n",
    "with mlflow.start_run(run_name='PARENT_RUN') as parent_run:\n",
    "    mlflow.log_param(\"parent\", \"yes\")\n",
    "    with mlflow.start_run(run_name='CHILD 1', nested=True) as child_run:\n",
    "        mlflow.log_param(\"child\", 1)\n",
    "\n",
    "    with mlflow.start_run(run_name='CHILD 2', nested=True) as child_run:\n",
    "        mlflow.log_param(\"child\", 2)\n",
    "\n",
    "\n",
    "# closing the ssh session\n",
    "ssh_session.kill()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the parent info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding the experiment id\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "experiment_name = 'expanding_dataset_aim1_2'\n",
    "experiment_id = client.get_experiment_by_name(experiment_name).experiment_id\n",
    "\n",
    "# getting the parent session info\n",
    "mlflow.list_run_infos(experiment_id=experiment_id)\n",
    "run_id_parent   = '329102d83efe4586a307bac05c92c298'\n",
    "parent_session = mlflow.get_run(run_id_parent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runnnig an mlflow project from github\n",
    "Run MLflow project and create a reproducible conda environment on a local host"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "github_repo = \"https://github.com/mlflow/mlflow-example\"\n",
    "params = {\"max_sample\": 2000,\"epoch\": 1}\n",
    "\n",
    "\n",
    "mlflow.run(uri=github_repo, parameters=params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loading the model from remote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  models:/<model_name>/<model_version>\n",
    "model = mlflow.keras.load_model(model_uri='models:/Chexpert-whole-dataset/1',compile=False)\n",
    "\n",
    "# models:/<model_name>/<stage> \n",
    "model = mlflow.keras.load_model(model_uri='models:/Chexpert-whole-dataset/production',compile=False)\n",
    "\n",
    "#  runs:/<mlflow_run_id>/run-relative-path-to-model\n",
    "run_id = 'f7d6e3b515da4ed89578cdd53412fcf8'\n",
    "model = mlflow.keras.load_model(model_uri='runs:/{}/model'.format(run_id),compile=False)\n",
    "\n",
    "# /Users/me/path/to/local/model\n",
    "model = mlflow.keras.load_model(model_uri='/home/u29/mohammadsmajdi/projects/chest_xray/artifacts_optimized_model/model',compile=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the artifact from remote server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Downloading the test results\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "\n",
    "local_dir = '../../'\n",
    "full_path = client.download_artifacts(run_id=run_id_parent, path='test_results.json', dst_path=local_dir)\n",
    "\n",
    "# Loading the downloaded json file\n",
    "score = pd.read_json(full_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Searching experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = mlflow.search_runs(experiment_id, \"params.max_sample > 20000”)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class containing all above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SSH_HOST' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/personal-macbook/Documents/projects/mlflow_workflow/mlflow.ipynb Cell 46'\u001b[0m in \u001b[0;36m<cell line: 260>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/personal-macbook/Documents/projects/mlflow_workflow/mlflow.ipynb#ch0000047?line=253'>254</a>\u001b[0m             mlflow\u001b[39m.\u001b[39mlog_artifact(path, artifact_path\u001b[39m=\u001b[39martifact_path)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/personal-macbook/Documents/projects/mlflow_workflow/mlflow.ipynb#ch0000047?line=258'>259</a>\u001b[0m \u001b[39m# Example:\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/personal-macbook/Documents/projects/mlflow_workflow/mlflow.ipynb#ch0000047?line=259'>260</a>\u001b[0m MLFLOW_SETUP(SSH_HOST     \u001b[39m=\u001b[39m SSH_HOST, \n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/personal-macbook/Documents/projects/mlflow_workflow/mlflow.ipynb#ch0000047?line=260'>261</a>\u001b[0m              SSH_USER     \u001b[39m=\u001b[39m SSH_USER, \n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/personal-macbook/Documents/projects/mlflow_workflow/mlflow.ipynb#ch0000047?line=261'>262</a>\u001b[0m              SSH_PORT     \u001b[39m=\u001b[39m SSH_PORT, \n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/personal-macbook/Documents/projects/mlflow_workflow/mlflow.ipynb#ch0000047?line=262'>263</a>\u001b[0m              SSH_KEY      \u001b[39m=\u001b[39m SSH_KEY, \n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/personal-macbook/Documents/projects/mlflow_workflow/mlflow.ipynb#ch0000047?line=263'>264</a>\u001b[0m              DATABASE     \u001b[39m=\u001b[39m DATABASE,       \n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/personal-macbook/Documents/projects/mlflow_workflow/mlflow.ipynb#ch0000047?line=264'>265</a>\u001b[0m              LOCAL_PORT   \u001b[39m=\u001b[39m LOCAL_PORT,       \n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/personal-macbook/Documents/projects/mlflow_workflow/mlflow.ipynb#ch0000047?line=265'>266</a>\u001b[0m              ARTIFACT_DIR \u001b[39m=\u001b[39m ARTIFACT_DIR,\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/personal-macbook/Documents/projects/mlflow_workflow/mlflow.ipynb#ch0000047?line=266'>267</a>\u001b[0m              DATABASE_USER_PASSWORD \u001b[39m=\u001b[39m DATABASE_USER_PASSWORD)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SSH_HOST' is not defined"
     ]
    }
   ],
   "source": [
    "class MLFLOW_SETUP():\n",
    "    \n",
    "    def __init__(self, SSH_HOST=\"SSH_HOST\", LOCAL_PORT=5000, SSH_USER=\"SSH_USER\", SSH_PORT=5432, SSH_KEY=\"SSH_KEY\", DATABASE='aiira', DATABASE_USER_PASSWORD=1234, ARTIFACT_DIR=\"path-to-artifact_store\"):\n",
    "   \n",
    "        # Hostname or IP address of the machine to tunnel to.\n",
    "        self.SSH_HOST     = SSH_HOST\n",
    "        \n",
    "        # Port on the remote machine to tunnel to.\n",
    "        self.SSH_PORT     = SSH_PORT\n",
    "        \n",
    "        # Local port to bind to.\n",
    "        self.LOCAL_PORT   = LOCAL_PORT\n",
    "        \n",
    "        # Username for SSH authentication.\n",
    "        self.SSH_USER     = SSH_USER\n",
    "        \n",
    "        # Path to the SSH private key file.\n",
    "        self.SSH_KEY      = SSH_KEY\n",
    "        \n",
    "        # Artifact storage directory\n",
    "        self.ARTIFACT_DIR = ARTIFACT_DIR\n",
    "        \n",
    "        # Database name\n",
    "        self.DATABASE     = DATABASE\n",
    "        \n",
    "        # Database user password\n",
    "        self.DATABASE_USER_PASSWORD = DATABASE_USER_PASSWORD\n",
    "                \n",
    "    def ssh_tunneling(self):\n",
    "\n",
    "        \"\"\"  Open a SSH tunnel from a local port to a remote host.\n",
    "        \n",
    "            Parameters\n",
    "            ----------\n",
    "            SSH_HOST : str\n",
    "                Hostname or IP address of the machine to tunnel to.\n",
    "            SSH_PORT : int\n",
    "                Port on the remote machine to tunnel to.\n",
    "            SSH_USER : str\n",
    "                Username for SSH authentication.\n",
    "            SSH_KEY : str\n",
    "                Path to the SSH private key file.\n",
    "            LOCAL_PORT : int, optional\n",
    "                Local port to bind to.\n",
    "\n",
    "\n",
    "            Returns\n",
    "            -------\n",
    "            tunnel : SSHClient\n",
    "                SSH client used to create the tunnel.\n",
    "                    \n",
    "                        \n",
    "            Command (in CLI)\n",
    "            -------\n",
    "                > ssh -L -N {LOCAL_PORT}:localhost:{SSH_PORT} -i {SSH_KEY} {SSH_USER}@{SSH_HOST} &\n",
    "                \n",
    "                \n",
    "            Saving the ssh credentials (in CLI)\n",
    "            --------------------------\n",
    "                > ssh-keygen -t rsa\n",
    "                > ssh-copy-id -i {SSH_KEY}  {SSH_USER}@{SSH_HOST}\n",
    "\n",
    "\n",
    "            Killing the ssh-tunnel (in SCRIPT)\n",
    "            ----------------------\n",
    "                > ssh_session.kill()\n",
    "                \n",
    "        \"\"\"\n",
    "        \n",
    "        command     = f'ssh -N -L {self.LOCAL_PORT}:localhost:{self.SSH_PORT} {self.SSH_USER}@{self.SSH_HOST} &'\n",
    "\n",
    "        self.ssh_session = subprocess.Popen('exec ' + command, stdout=subprocess.PIPE, shell=True)\n",
    "        \n",
    "        # Waits until session process is finished\n",
    "        self.ssh_session.wait()\n",
    "        print(\"ssh tunnel is running\")\n",
    "        \n",
    "        return self.ssh_session\n",
    "\n",
    "    def mlflow_ui(self, VIEW_PORT=6789):\n",
    "        \"\"\" Running the ui locally\n",
    "        \n",
    "        Args:\n",
    "            VIEW_PORT (int, default=6789): port used for viewing mlflow server.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.VIEW_PORT = VIEW_PORT\n",
    "        \n",
    "        if subprocess.call(['nc', '-z', 'localhost', str(VIEW_PORT)]) == 0: \n",
    "            print(f\"MLFlow UI is already running on localhost:{VIEW_PORT}\")\n",
    "            return None\n",
    "\n",
    "        command = f'mlflow ui --backend-store-uri postgresql://{self.SSH_USER}:{self.DATABASE_USER_PASSWORD}@localhost:{self.LOCAL_PORT}/{self.DATABASE} --port {VIEW_PORT}'\n",
    "        p = subprocess.Popen('exec ' + command, stdout=subprocess.PIPE, shell=True)\n",
    "        return p\n",
    "                 \n",
    "    def _mlflow_settings(self,view_mode='local'):\n",
    "        \n",
    "        \"\"\" Postgres server can be set to either the local port (mapped to remote port through ssh-tunneling) or directly with the remote port.\n",
    "                 \n",
    "                              PORT     HOST \n",
    "                              ----    -----------------------\n",
    "            Remote Server:    5432    'data7-db1.cyverse.org'\n",
    "            Local  Server:    5000    'localhost'\n",
    "            \n",
    "            PostgreSQL Server: f'{dialect_driver}://{username}:{password}@{ip}/{database_name}' \n",
    "            \n",
    "            Artifact Server:   f'sftp://{username}@{host}:{path_to_artifact_store}' \n",
    "\n",
    "         \"\"\"\n",
    "\n",
    "        HOST = self.SSH_HOST if view_mode == 'remote' else 'localhost'\n",
    "        PORT = self.SSH_PORT if view_mode == 'remote' else '5000'\n",
    "            \n",
    "        self.server = f'postgresql://{self.SSH_USER}:{self.DATABASE_USER_PASSWORD}@{HOST}:{PORT}/{self.DATABASE}'\n",
    "        \n",
    "        \n",
    "        \"\"\" Artifact store is always kept on the remote server in this particular example.\n",
    "            \n",
    "            The artifact store is the location where clients log their artifact output (such as an S3 bucket or shared NFS file) (for example, models). \n",
    "            \n",
    "            Notes:\n",
    "                - Artifact location: is a property recorded in \"mlflow.entities.Experiment\" for all runs of this experiment. \n",
    "                - Artifact uri: is a property recorded in \"mlflow.entities.RunInfo\" that specifies the location of all artifacts for this run.\n",
    "\n",
    "            In each run, the MLflow client stores the location of artifacts. It is therefore not advised to alter the artifact location of a run before it has finished.\n",
    "\n",
    "            We can set the default artifact storage location with —default-artifact-root. (default: ./mlruns in local directory) \n",
    "            \n",
    "            Notes:\n",
    "                - This will be used for new experiments that do not provide an artifact location. \n",
    "                - -default-artifact-root is no longer valid once an experiment has been setup.\n",
    "                - Using the —serve-artifacts flag enables proxying of artifacts. It replaces an explicit artifact storage location (such as \"s3:/my bucket/mlartifacts\") with an implicit location. Sending HTTP requests to the MLflow Tracking Server does this. When publishing or retrieving artifacts, this avoids the need to configure access tokens or username/password environment variables for the underlying object storage.\n",
    "\n",
    "            SUPPORTED ARTIFACT STORES:\n",
    "        \n",
    "                - Amazon S3 and S3-compatible storage\n",
    "                - Azure Blob Storage\n",
    "                - Google Cloud Storage\n",
    "                - FTP server\n",
    "                - SFTP Server\n",
    "                - NFS\n",
    "                - HDFS\n",
    "        \"\"\"\n",
    "        \n",
    "        self.artifact = f'sftp://{self.SSH_USER}@{self.SSH_HOST}:{self.ARTIFACT_DIR}'\n",
    "\n",
    "        return self.server, self.artifact\n",
    "\n",
    "    def experiment_setup(self, experiment_name='experiment_name', view_mode=\"local\", table_name=\"table_name\"):\n",
    "        \"\"\" Setting up the experiment \"\"\"\n",
    "                    \n",
    "        self.view_mode       = view_mode\n",
    "        self.table_name      = table_name\n",
    "        self.experiment_name = experiment_name\n",
    "                \n",
    "        server, artifact = self._mlflow_settings()\n",
    "        mlflow.set_tracking_uri(server)\n",
    "\n",
    "\n",
    "        self.client = mlflow.tracking.MlflowClient()\n",
    "        \n",
    "        if not self.client.get_experiment_by_name(self.experiment_name):\n",
    "            mlflow.create_experiment(name=self.experiment_name, artifact_location=artifact)\n",
    "\n",
    "        mlflow.set_experiment(experiment_name=self.experiment_name)\n",
    "\n",
    "\n",
    "    def _getting_the_list_of_all_runs(self, path_run_id_list='results/run_id_list.csv'):\n",
    "        \n",
    "        if os.path.isfile(path_run_id_list):\n",
    "            self.run_id_list = pd.read_csv(path_run_id_list, index_col=0).to_dict()['run_id']\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            # getting the experiment ID corresponding to our experiment name\n",
    "            self.experiment_id = self.client.get_experiment_by_name(self.experiment_name).experiment_id\n",
    "\n",
    "            # looping through all runs in the experiment\n",
    "            self.run_id_list = {}\n",
    "            for run_info in tqdm(self.client.list_run_infos(self.experiment_id), desc='Getting the list of all runs'):\n",
    "                \n",
    "                # getting the simulation/run name corresponding to run_id\n",
    "                run_name = mlflow.get_run(run_info.run_id).data.tags['mlflow.runName']\n",
    "                \n",
    "                # adding the run name to the dictionary containnig all run id/name pairs\n",
    "                self.run_id_list[run_name] = run_info.run_id\n",
    "            \n",
    "            os.makedirs(os.path.dirname(path_run_id_list), exist_ok=True)\n",
    "            pd.DataFrame.from_dict(self.run_id_list, orient='index', columns=['run_id']).to_csv(path_run_id_list)\n",
    "\n",
    "        return self.run_id_list\n",
    "                \n",
    "    def _downloading_artifacts(self):\n",
    "        \n",
    "        \"\"\" Downloading the artifacts from the remote server \"\"\"\n",
    "        \n",
    "        print('Downloading the artifacts...', end=' ')\n",
    "        \n",
    "        # creating the artifact directory\n",
    "        os.makedirs(self.dst_path, exist_ok=True)\n",
    "        \n",
    "        # downloading the artifacts from the remote server\n",
    "        self.client.download_artifacts(run_id = self.run.info.run_id, dst_path=self.dst_path, path='')\n",
    "        \n",
    "        print('   Completed')\n",
    "                 \n",
    "    def get_run(self, run_name='run_name', dst_path='results/', download=True):\n",
    "\n",
    "        # getting the list of all runs for our experiment\n",
    "        self._getting_the_list_of_all_runs()  \n",
    "        \n",
    "        # print('Getting the mlflow run')\n",
    "        self.run = mlflow.get_run(self.run_id_list[run_name])\n",
    "\n",
    "        self.dst_path = dst_path\n",
    "        \n",
    "        # downloading the artifacts for our desired run/simulation\n",
    "        if download: self._downloading_artifacts()\n",
    "        \n",
    "    def run_setup(self, run_name=None, run_id=None, new_run=True):\n",
    "        \n",
    "        if new_run: \n",
    "            self.run = mlflow.start_run(run_name=run_name) \n",
    "            mlflow.set_tag(f'mlflow.note.content',f'run_id: {self.run.info.run_id}')\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            if run_id is None:\n",
    "                self._getting_the_list_of_all_runs()\n",
    "                run_id = self.run_id_list[run_name]\n",
    "                \n",
    "            self.run = mlflow.start_run(run_id=run_id)\n",
    "        \n",
    "        # saving the git commit hash inside run\n",
    "        repo = git.Repo(search_parent_directories=True)\n",
    "        mlflow.set_tag('mlflow.source.git.commit', repo.head.object.hexsha)\n",
    "        mlflow.set_tag('mlflow.source.name'      , self.run.data.tags['mlflow.source.name'])\n",
    "                \n",
    "    def log_artifact(self, data={}, data_type='dict', path='', artifact_path='', upload_artifact=True):\n",
    "        \n",
    "        if upload_artifact:\n",
    "            path_dir = os.path.dirname(os.path.abspath(path))\n",
    "            os.makedirs(path_dir, exist_ok=True)\n",
    "                \n",
    "            if data_type == 'figure': data.savefig(path, dpi=600)\n",
    "                \n",
    "            elif data_type == 'dict':\n",
    "                with open(path, 'wb') as f:\n",
    "                    pickle.dump(data, f)\n",
    "                    \n",
    "            elif data_type == 'csv': data.to_csv(path)\n",
    "                \n",
    "            mlflow.log_artifact(path, artifact_path=artifact_path)\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "# Example:\n",
    "MLFLOW_SETUP(SSH_HOST     = SSH_HOST, \n",
    "             SSH_USER     = SSH_USER, \n",
    "             SSH_PORT     = SSH_PORT, \n",
    "             SSH_KEY      = SSH_KEY, \n",
    "             DATABASE     = DATABASE,       \n",
    "             LOCAL_PORT   = LOCAL_PORT,       \n",
    "             ARTIFACT_DIR = ARTIFACT_DIR,\n",
    "             DATABASE_USER_PASSWORD = DATABASE_USER_PASSWORD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b7507cad7674224fddfb61f8fb498d6d14e39093b8261cc8bda96762d4534d46"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('mlflow_latest')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "metadata": {
   "interpreter": {
    "hash": "97f50b47c5db4a373caba7d351ed0bd803d6a9b66b6e99b50d57389022e4f55d"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
